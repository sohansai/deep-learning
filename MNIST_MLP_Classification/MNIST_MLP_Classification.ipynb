{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Import the MNIST dataset from TensorFlow\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "# Load the training and testing data\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Reshape the data for Multilayer Perceptron (MLP) input\n",
        "import numpy as np\n",
        "\n",
        "train_images = np.reshape(train_images, (-1, 784))\n",
        "test_images = np.reshape(test_images, (-1, 784))\n",
        "\n",
        "# Normalize the data to values between 0 and 1\n",
        "train_images = train_images.astype('float32') / 255\n",
        "test_images = test_images.astype('float32') / 255\n",
        "\n",
        "# Convert labels to a one-hot vector\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "\n",
        "# Define the architecture of the neural network\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import InputLayer, Dense\n",
        "\n",
        "MLP = Sequential()\n",
        "MLP.add(InputLayer(input_shape=(784, )))  # Input layer\n",
        "MLP.add(Dense(256, activation='relu'))    # Hidden layer 1\n",
        "MLP.add(Dense(256, activation='relu'))    # Hidden layer 2\n",
        "MLP.add(Dense(10, activation='softmax'))  # Output layer\n",
        "\n",
        "# Display a summary of the network architecture\n",
        "MLP.summary()\n",
        "\n",
        "# Compile the model with loss, optimizer, and evaluation metric\n",
        "MLP.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model on the training data\n",
        "MLP.fit(train_images, train_labels, epochs=20, batch_size=128)\n",
        "\n",
        "# Evaluate the performance of the model on the test data\n",
        "test_loss, test_acc = MLP.evaluate(test_images, test_labels, batch_size=128, verbose=0)\n",
        "print(\"Test loss:\", test_loss)\n",
        "print(\"Test accuracy:\", test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAkd5HRBwUJf",
        "outputId": "c072b7b6-d112-490d-ea2c-46c9d51b3db4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 256)               200960    \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 269322 (1.03 MB)\n",
            "Trainable params: 269322 (1.03 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.2584 - accuracy: 0.9257\n",
            "Epoch 2/20\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.0974 - accuracy: 0.9704\n",
            "Epoch 3/20\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0644 - accuracy: 0.9803\n",
            "Epoch 4/20\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.0463 - accuracy: 0.9854\n",
            "Epoch 5/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0341 - accuracy: 0.9892\n",
            "Epoch 6/20\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0270 - accuracy: 0.9912\n",
            "Epoch 7/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0219 - accuracy: 0.9932\n",
            "Epoch 8/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0170 - accuracy: 0.9942\n",
            "Epoch 9/20\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0166 - accuracy: 0.9946\n",
            "Epoch 10/20\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0123 - accuracy: 0.9955\n",
            "Epoch 11/20\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.0149 - accuracy: 0.9952\n",
            "Epoch 12/20\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0110 - accuracy: 0.9963\n",
            "Epoch 13/20\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0098 - accuracy: 0.9967\n",
            "Epoch 14/20\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.0086 - accuracy: 0.9972\n",
            "Epoch 15/20\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0114 - accuracy: 0.9963\n",
            "Epoch 16/20\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0102 - accuracy: 0.9967\n",
            "Epoch 17/20\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.0066 - accuracy: 0.9977\n",
            "Epoch 18/20\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0082 - accuracy: 0.9971\n",
            "Epoch 19/20\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0090 - accuracy: 0.9972\n",
            "Epoch 20/20\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.0075 - accuracy: 0.9975\n",
            "Test loss: 0.09063573181629181\n",
            "Test accuracy: 0.9811000227928162\n"
          ]
        }
      ]
    }
  ]
}